import requests
import json
import os
import re
import time
from datetime import datetime
from bs4 import BeautifulSoup

# -- Cáº¥u hÃ¬nh --
API_KEY = os.environ["GEMINI_API_KEY"]
MODEL = "gemini-1.5-flash"
API_URL = f"https://generativelanguage.googleapis.com/v1/models/{MODEL}:generateContent?key={API_KEY}"

ALBUMS = [
    "https://mp.weixin.qq.com/mp/appmsgalbum?action=getalbum&__biz=MzU5NjU1NjY1Mw==&album_id=3447004682407854082&f=json",
    "https://mp.weixin.qq.com/mp/appmsgalbum?action=getalbum&__biz=MzkyMjc1NzEzOA==&album_id=3646379824391471108&f=json",
    "https://mp.weixin.qq.com/mp/appmsgalbum?action=getalbum&__biz=MzI1MDQ1MjUxNw==&album_id=3664489989179457545&f=json"
]

# -- Báº£ng tá»« chuyÃªn ngÃ nh --
GLOSSARY = {
    "æµ": "lá»‘i chÆ¡i",
    "æœ¨æ¡©": "cá»c gá»—",
    "æ²§æ¾œ": "ThÆ°Æ¡ng Lan",
    "æ½®å…‰": "Triá»u Quang",
    "ç„æœº": "Huyá»n CÆ¡",
    "é¾™åŸ": "Long NgÃ¢m",
    "ç¥ç›¸": "Tháº§n TÆ°Æ¡ng",
    "è¡€æ²³": "Huyáº¿t HÃ ",
    "ç¢æ¢¦": "ToÃ¡i Má»™ng",
    "ç´ é—®": "Tá»‘ Váº¥n",
    "ä¹çµ": "Cá»­u Linh",
    "é“è¡£": "Thiáº¿t Y"
}

def cleanup_translation(text):
    text = re.sub(r"\*\*.*?\*\*", "", text)
    text = re.sub(r"\n+", "\n", text)
    text = re.sub(r"\s{2,}", " ", text)
    return text.strip()

def fix_terms(text):
    for zh, vi in GLOSSARY.items():
        text = text.replace(zh, vi)
    return text

def has_chinese_chars(s):
    """Kiá»ƒm tra xem chuá»—i cÃ³ chá»©a kÃ½ tá»± tiáº¿ng Trung hay khÃ´ng."""
    return re.search(r'[\u4e00-\u9fff]', s)

def translate_plain_text_zh_to_vi(text, retries=3, delay=25):
    """Dá»‹ch vÄƒn báº£n thuáº§n tÃºy, vá»›i cÆ¡ cháº¿ thá»­ láº¡i vÃ  xÃ¡c thá»±c káº¿t quáº£."""
    if not text or not text.strip():
        return ""

    headers = {"Content-Type": "application/json"}
    prompt = (
        "Báº¡n lÃ  má»™t chuyÃªn gia dá»‹ch thuáº­t tiáº¿ng Trung - Viá»‡t, chuyÃªn vá» game 'Nghá»‹ch Thá»§y HÃ n Mobile'.\n"
        "HÃ£y dá»‹ch ná»™i dung sau sang tiáº¿ng Viá»‡t má»™t cÃ¡ch tá»± nhiÃªn, chÃ­nh xÃ¡c, giá»¯ nguyÃªn cÃ¡c dáº¥u xuá»‘ng dÃ²ng.\n"
        "KhÃ´ng thÃªm báº¥t ká»³ bÃ¬nh luáº­n, ghi chÃº hay lá»i chÃ o nÃ o.\n\n"
        f"Ná»™i dung cáº§n dá»‹ch:\n{text}"
    )
    payload = {
        "contents": [{"parts": [{"text": prompt}]}],
        "generationConfig": {"temperature": 0.4}
    }

    for attempt in range(retries):
        try:
            response = requests.post(API_URL, headers=headers, json=payload, timeout=120)
            if response.status_code == 200:
                result = response.json()
                translated_text = result["candidates"][0]["content"]["parts"][0]["text"]
                
                # XÃ¡c thá»±c káº¿t quáº£: náº¿u váº«n cÃ²n tiáº¿ng Trung, coi nhÆ° tháº¥t báº¡i
                if has_chinese_chars(translated_text) and len(translated_text) > len(text) * 0.5:
                    print(f"    âš ï¸ Dá»‹ch cÃ³ váº» tháº¥t báº¡i (cÃ²n tiáº¿ng Trung). Thá»­ láº¡i láº§n {attempt + 1}/{retries}...")
                    time.sleep(delay * (attempt + 1))
                    continue # Bá» qua vÃ  thá»­ láº¡i

                print("    âœ… Dá»‹ch vÄƒn báº£n thÃ nh cÃ´ng.")
                return fix_terms(translated_text)
            elif response.status_code in [429, 503]:
                wait_time = delay * (attempt + 1)
                print(f"    âš ï¸ Lá»—i {response.status_code}. Thá»­ láº¡i sau {wait_time}s...")
                time.sleep(wait_time)
            else:
                print(f"    âŒ Lá»—i dá»‹ch: {response.status_code} - {response.text}")
                # KhÃ´ng tráº£ vá» chuá»—i rá»—ng ngay, thá»­ láº¡i á»Ÿ láº§n tiáº¿p theo
                time.sleep(delay * (attempt + 1))

        except requests.exceptions.RequestException as e:
            print(f"    âŒ Lá»—i máº¡ng khi dá»‹ch: {e}. Thá»­ láº¡i sau {delay}s...")
            time.sleep(delay)

    print(f"    âŒ Thá»­ láº¡i nhiá»u láº§n nhÆ°ng váº«n lá»—i. Tráº£ vá» vÄƒn báº£n gá»‘c cho: '{text[:30]}...' ")
    return text # Tráº£ vá» vÄƒn báº£n gá»‘c náº¿u dá»‹ch tháº¥t báº¡i hoÃ n toÃ n

def batch_translate_zh_to_vi(text_blocks, retries=3, delay=20, chunk_char_limit=5000):
    """Dá»‹ch hÃ ng loáº¡t, há»— trá»£ chia nhá» khá»‘i vÄƒn báº£n dÃ i vÃ  xÃ¡c thá»±c káº¿t quáº£."""
    if not text_blocks:
        return []

    # --- Logic chia nhá» (Chunking) ---
    chunks = []
    current_chunk = []
    current_length = 0
    for block in text_blocks:
        if current_length + len(block) > chunk_char_limit and current_chunk:
            chunks.append(current_chunk)
            current_chunk = []
            current_length = 0
        current_chunk.append(block)
        current_length += len(block)
    if current_chunk:
        chunks.append(current_chunk)
    
    all_translated_blocks = []
    for i, chunk in enumerate(chunks):
        print(f"    ğŸ“¦ Äang dá»‹ch gÃ³i {i + 1}/{len(chunks)} ({len(chunk)} khá»‘i vÄƒn báº£n)..._ ")
        translated_chunk = _translate_chunk(chunk, retries, delay)
        if translated_chunk:
            all_translated_blocks.extend(translated_chunk)
        else:
            # Náº¿u má»™t gÃ³i bá»‹ lá»—i, tráº£ vá» toÃ n bá»™ vÄƒn báº£n gá»‘c Ä‘á»ƒ Ä‘áº£m báº£o tÃ­nh toÃ n váº¹n
            print("    âŒ Má»™t gÃ³i dá»‹ch bá»‹ lá»—i, sáº½ giá»¯ láº¡i toÃ n bá»™ vÄƒn báº£n gá»‘c cho bÃ i viáº¿t nÃ y.")
            return text_blocks 

    return all_translated_blocks

def _translate_chunk(chunk, retries=3, delay=20):
    """HÃ m phá»¥, dá»‹ch má»™t gÃ³i vÄƒn báº£n duy nháº¥t."""
    joined_text = "\n".join(chunk)
    prompt = (
        "Báº¡n lÃ  má»™t chuyÃªn gia dá»‹ch thuáº­t tiáº¿ng Trung - Viá»‡t, chuyÃªn vá» game 'Nghá»‹ch Thá»§y HÃ n Mobile'.\n"
        "HÃ£y dá»‹ch cÃ¡c Ä‘oáº¡n vÄƒn báº£n sau sang tiáº¿ng Viá»‡t. Má»—i Ä‘oáº¡n Ä‘Æ°á»£c phÃ¢n tÃ¡ch báº±ng dáº¥u xuá»‘ng dÃ²ng.\n"
        "**YÃŠU Cáº¦U TUYá»†T Äá»I:**\n"
        "1. **Dá»ŠCH TOÃ€N Bá»˜:** KhÃ´ng Ä‘Æ°á»£c bá» sÃ³t báº¥t ká»³ cÃ¢u, tá»« hay chi tiáº¿t nÃ o.\n"
        "2. **GIá»® NGUYÃŠN Sá» LÆ¯á»¢NG:** Pháº£i tráº£ vá» chÃ­nh xÃ¡c cÃ¹ng sá»‘ lÆ°á»£ng Ä‘oáº¡n vÄƒn nhÆ° Ä‘Ã£ nháº­n.\n"
        "3. **KHÃ”NG THÃŠM THáº®T:** KhÃ´ng thÃªm bÃ¬nh luáº­n, ghi chÃº, hay Ä‘á»‹nh dáº¡ng khÃ´ng cáº§n thiáº¿t.\n\n"
        f"CÃC ÄOáº N Cáº¦N Dá»ŠCH:\n{joined_text}"
    )
    payload = {
        "contents": [{"parts": [{"text": prompt}]}],
        "generationConfig": {"temperature": 0.4}
    }

    for attempt in range(retries):
        try:
            response = requests.post(API_URL, headers={"Content-Type": "application/json"}, json=payload, timeout=180)
            if response.status_code == 200:
                result = response.json()
                if not result.get('candidates') or not result['candidates'][0].get('content'):
                    print(f"    âš ï¸ Pháº£n há»“i API khÃ´ng há»£p lá»‡. Thá»­ láº¡i láº§n {attempt + 1}/{retries}...")
                    time.sleep(delay * (attempt + 1))
                    continue

                translated_text = result['candidates'][0]['content']['parts'][0]['text']
                translated_blocks = [fix_terms(line.strip()) for line in translated_text.split('\n') if line.strip()]
                
                if len(translated_blocks) != len(chunk):
                    print(f"    âš ï¸ Sá»‘ lÆ°á»£ng dÃ²ng tráº£ vá» ({len(translated_blocks)}) khÃ´ng khá»›p ({len(chunk)}). Thá»­ láº¡i...")
                    time.sleep(delay * (attempt + 1))
                    continue

                if any(has_chinese_chars(t) for t in translated_blocks):
                    print(f"    âš ï¸ Káº¿t quáº£ dá»‹ch váº«n chá»©a tiáº¿ng Trung. Thá»­ láº¡i láº§n {attempt + 1}/{retries}...")
                    time.sleep(delay * (attempt + 1))
                    continue

                print(f"    âœ… Dá»‹ch gÃ³i thÃ nh cÃ´ng vÃ  Ä‘Ã£ xÃ¡c thá»±c.")
                return translated_blocks

            elif response.status_code in [429, 503]:
                wait_time = delay * (attempt + 1)
                print(f"    âš ï¸ Lá»—i {response.status_code}. Thá»­ láº¡i sau {wait_time}s...")
                time.sleep(wait_time)
            else:
                print(f"    âŒ Lá»—i dá»‹ch: {response.status_code} - {response.text}")
                time.sleep(delay * (attempt + 1))
        except requests.exceptions.RequestException as e:
            print(f"    âŒ Lá»—i máº¡ng khi dá»‹ch: {e}")
            time.sleep(delay)

    print(f"    âŒ Dá»‹ch gÃ³i tháº¥t báº¡i sau nhiá»u láº§n thá»­.")
    return None # Tráº£ vá» None náº¿u tháº¥t báº¡i

    print("âŒ Thá»­ láº¡i nhiá»u láº§n nhÆ°ng váº«n lá»—i. Bá» qua dá»‹ch.")
    return titles

def fetch_articles(url):
    print("ğŸ” Äang láº¥y dá»¯ liá»‡u tá»« album...")
    headers = {
        "User-Agent": "Mozilla/5.0",
        "Accept": "application/json, text/plain, */*",
        "Referer": "https://mp.weixin.qq.com/",
        "X-Requested-With": "XMLHttpRequest"
    }
    resp = requests.get(url, headers=headers)
    data = resp.json()

    articles_raw = data.get("getalbum_resp", {}).get("article_list", [])
    items = []

    weekdays_vi = [
        "Thá»© Hai", "Thá»© Ba", "Thá»© TÆ°", "Thá»© NÄƒm",
        "Thá»© SÃ¡u", "Thá»© Báº£y", "Chá»§ Nháº­t"
    ]

    for art in articles_raw:
        title = art["title"]
        url = art["url"]
        cover = art.get("cover_img_1_1") or art.get("cover") or ""
        timestamp = int(art.get("create_time", 0))
        dt = datetime.utcfromtimestamp(timestamp)
        weekday = weekdays_vi[dt.weekday()]
        date_str = f"{dt.strftime('%H:%M')} - {weekday}, {dt.strftime('%d/%m')}"

        items.append({
            "title": title,
            "url": url,
            "cover_img": cover,
            "timestamp": timestamp,
            "date": date_str
        })

    print(f"âœ… {len(items)} bÃ i viáº¿t")
    return items

def fetch_article_details(url):
    """BÃ³c tÃ¡ch bÃ i viáº¿t thÃ nh cÃ¡c khá»‘i vÄƒn báº£n vÃ  hÃ¬nh áº£nh cÃ³ cáº¥u trÃºc."""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
        }
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()

        soup = BeautifulSoup(response.text, 'html.parser')
        content_div = soup.find('div', id='js_content')
        if not content_div:
            return None

        structured_content = []
        # Láº·p qua táº¥t cáº£ cÃ¡c tháº» con trá»±c tiáº¿p trong div ná»™i dung
        for element in content_div.find_all(recursive=False):
            # TÃ¬m táº¥t cáº£ áº£nh trong element hiá»‡n táº¡i
            images_in_element = element.find_all('img')
            text_in_element = element.get_text(strip=True)

            if images_in_element:
                for img in images_in_element:
                    img_src = img.get('data-src') or img.get('src')
                    if img_src:
                        structured_content.append({'type': 'image', 'url': img_src})
            elif text_in_element:
                # Chá»‰ thÃªm khá»‘i vÄƒn báº£n náº¿u nÃ³ cÃ³ ná»™i dung
                structured_content.append({'type': 'text', 'content': text_in_element})

        return {
            'structured_content': structured_content
        }
    except requests.exceptions.RequestException as e:
        print(f"    âŒ Lá»—i khi táº£i chi tiáº¿t bÃ i viáº¿t: {e}")
        return None
    except Exception as e:
        print(f"    âŒ Lá»—i khÃ´ng xÃ¡c Ä‘á»‹nh khi xá»­ lÃ½ chi tiáº¿t bÃ i viáº¿t: {e}")
        return None

def fetch_all_albums(album_urls):
    all_articles = []
    for url in album_urls:
        articles = fetch_articles(url)
        top_4 = sorted(articles, key=lambda x: x["timestamp"], reverse=True)[:4]
        all_articles.extend(top_4)
    sorted_articles = sorted(all_articles, key=lambda x: x["timestamp"], reverse=True)
    return sorted_articles

# -- MAIN --
if __name__ == "__main__":
    # B1: Táº£i cache tá»« news.json náº¿u cÃ³
    existing_news_map = {}
    if os.path.exists("news.json"):
        try:
            with open("news.json", "r", encoding="utf-8") as f:
                old_news_list = json.load(f)
                for item in old_news_list:
                    if item.get("url"):
                        existing_news_map[item["url"]] = item
            print(f"âœ… ÄÃ£ táº£i {len(existing_news_map)} bÃ i viáº¿t tá»« cache.")
        except (json.JSONDecodeError, FileNotFoundError):
            print("âš ï¸ KhÃ´ng thá»ƒ Ä‘á»c file cache news.json, sáº½ táº¡o má»›i tá»« Ä‘áº§u.")
            existing_news_map = {}

    # B2: Láº¥y danh sÃ¡ch bÃ i viáº¿t má»›i nháº¥t tá»« cÃ¡c album
    articles_from_source = fetch_all_albums(ALBUMS)

    # B3: Lá»c thÃ´ng minh: XÃ¡c Ä‘á»‹nh bÃ i má»›i, bÃ i cáº§n dá»‹ch láº¡i, vÃ  bÃ i Ä‘Ã£ hoÃ n chá»‰nh
    articles_to_process = []
    final_news = []
    print("\nğŸ” Báº¯t Ä‘áº§u lá»c vÃ  phÃ¢n loáº¡i bÃ i viáº¿t...")
    for article in articles_from_source:
        url = article['url']
        if url not in existing_news_map:
            print(f"  - [Má»šI] {article['title']}")
            articles_to_process.append(article)
        else:
            cached_article = existing_news_map[url]
            is_title_translated = 'title_vi' in cached_article and cached_article['title_vi'] and not has_chinese_chars(cached_article['title_vi'])
            
            is_content_translated = True
            if 'structured_content_vi' in cached_article and cached_article['structured_content_vi']:
                for block in cached_article['structured_content_vi']:
                    if block['type'] == 'text' and has_chinese_chars(block['content']):
                        is_content_translated = False
                        break
            else:
                is_content_translated = False

            if not is_title_translated or not is_content_translated:
                print(f"  - [Dá»ŠCH Láº I] {article['title']}")
                articles_to_process.append(article)
            else:
                # BÃ i Ä‘Ã£ dá»‹ch hoÃ n chá»‰nh, giá»¯ láº¡i tá»« cache nhÆ°ng cáº­p nháº­t ngÃ y
                cached_article['date'] = article['date']
                final_news.append(cached_article)

    print(f"\n=> ğŸ“Š Tá»•ng cá»™ng cÃ³ {len(articles_to_process)} bÃ i viáº¿t cáº§n xá»­ lÃ½.")

    # B4: Xá»­ lÃ½ cÃ¡c bÃ i viáº¿t cáº§n thiáº¿t
    if articles_to_process:
        for i, article_summary in enumerate(articles_to_process):
            print(f"\n[{i+1}/{len(articles_to_process)}] Äang xá»­ lÃ½: {article_summary['title']}")
            article_url = article_summary['url']

            # Dá»‹ch tiÃªu Ä‘á» (dá»‹ch Ä‘Æ¡n láº» Ä‘á»ƒ Ä‘áº£m báº£o chÃ­nh xÃ¡c)
            print("    â¡ï¸  Äang dá»‹ch tiÃªu Ä‘á»...")
            vi_title = translate_plain_text_zh_to_vi(article_summary["title"])
            print(f"    â¡ï¸  TiÃªu Ä‘á» VI: {vi_title}")

            # Láº¥y chi tiáº¿t bÃ i viáº¿t (chá»‰ khi cáº§n dá»‹ch ná»™i dung)
            print("    â†ªï¸  Äang táº£i vÃ  phÃ¢n tÃ­ch ná»™i dung...")
            details = fetch_article_details(article_url)
            if not details:
                print(f"    âŒ KhÃ´ng thá»ƒ táº£i chi tiáº¿t cho: {article_summary['title']}")
                continue

            # TÃ¡ch vÃ  dá»‹ch cÃ¡c khá»‘i vÄƒn báº£n
            text_blocks_to_translate = [block['content'] for block in details['structured_content'] if block['type'] == 'text' and block['content'].strip()]
            if text_blocks_to_translate:
                translated_blocks = batch_translate_zh_to_vi(text_blocks_to_translate)
                if len(translated_blocks) == len(text_blocks_to_translate):
                    # GhÃ©p láº¡i ná»™i dung Ä‘Ã£ dá»‹ch vÃ o cáº¥u trÃºc
                    translated_content_iterator = iter(translated_blocks)
                    for block in details['structured_content']:
                        if block['type'] == 'text' and block['content'].strip():
                            block['content'] = next(translated_content_iterator)
                else:
                    print(f"    âŒ Dá»‹ch ná»™i dung tháº¥t báº¡i, sá»‘ khá»‘i tráº£ vá» khÃ´ng khá»›p. Sáº½ giá»¯ láº¡i ná»™i dung gá»‘c.")
            
            # Táº¡o Ä‘á»‘i tÆ°á»£ng bÃ i viáº¿t hoÃ n chá»‰nh
            full_article_data = {
                "title_zh": article_summary["title"],
                "title_vi": vi_title,
                "url": article_url,
                "cover_img": article_summary["cover_img"],
                "date": article_summary["date"],
                "structured_content_vi": details['structured_content']
            }
            final_news.append(full_article_data)
            print(f"    âœ… ÄÃ£ xá»­ lÃ½ xong: {vi_title}")
            time.sleep(10) # Nghá»‰ giá»¯a cÃ¡c bÃ i viáº¿t

    # B5: Káº¿t há»£p vÃ  lÆ°u káº¿t quáº£ cuá»‘i cÃ¹ng
    # Sáº¯p xáº¿p láº¡i danh sÃ¡ch cuá»‘i cÃ¹ng theo timestamp gá»‘c Ä‘á»ƒ Ä‘áº£m báº£o thá»© tá»±
    url_to_timestamp = {a['url']: a['timestamp'] for a in articles_from_source}
    final_news.sort(key=lambda x: url_to_timestamp.get(x['url'], 0), reverse=True)

    with open('news.json', 'w', encoding='utf-8') as f:
        json.dump(final_news, f, ensure_ascii=False, indent=2)

    print("\nğŸ‰ HoÃ n táº¥t! File news.json Ä‘Ã£ Ä‘Æ°á»£c cáº­p nháº­t vá»›i logic cache thÃ´ng minh.")
