import requests
import json
import os
import re
import time
from datetime import datetime

# -- Cáº¥u hÃ¬nh --
# Há»— trá»£ nhiá»u API key Gemini (GEMINI_API_KEYS, ngÄƒn cÃ¡ch bá»Ÿi dáº¥u pháº©y)
API_KEYS = os.environ.get("GEMINI_API_KEYS")
if API_KEYS:
    GEMINI_API_KEYS = [k.strip() for k in API_KEYS.split(",") if k.strip()]
else:
    GEMINI_API_KEYS = [os.environ["GEMINI_API_KEY"]]
MODEL = "gemini-1.5-flash"
API_URL_TEMPLATE = "https://generativelanguage.googleapis.com/v1/models/{}:generateContent?key={}".format(MODEL, "{}")

ALBUMS = [
    "https://mp.weixin.qq.com/mp/appmsgalbum?action=getalbum&__biz=MzU5NjU1NjY1Mw==&album_id=3447004682407854082&f=json",
    "https://mp.weixin.qq.com/mp/appmsgalbum?action=getalbum&__biz=MzkyMjc1NzEzOA==&album_id=3646379824391471108&f=json",
    "https://mp.weixin.qq.com/mp/appmsgalbum?action=getalbum&__biz=MzI1MDQ1MjUxNw==&album_id=3664489989179457545&f=json"
]

# -- Báº£ng tá»« chuyÃªn ngÃ nh --
GLOSSARY = {
    "æµ": "lá»‘i chÆ¡i",
    "æœ¨æ¡©": "cá»c gá»—",
    "æ²§æ¾œ": "ThÆ°Æ¡ng Lan",
    "æ½®å…‰": "Triá»u Quang",
    "ç„æœº": "Huyá»n CÆ¡",
    "é¾™åŸ": "Long NgÃ¢m",
    "ç¥ç›¸": "Tháº§n TÆ°Æ¡ng",
    "è¡€æ²³": "Huyáº¿t HÃ ",
    "ç¢æ¢¦": "ToÃ¡i Má»™ng",
    "ç´ é—®": "Tá»‘ Váº¥n",
    "ä¹çµ": "Cá»­u Linh",
    "é“è¡£": "Thiáº¿t Y"
}

def cleanup_translation(text):
    text = re.sub(r"\*\*.*?\*\*", "", text)
    text = re.sub(r"\n+", "\n", text)
    text = re.sub(r"\s{2,}", " ", text)
    return text.strip()

def fix_terms(text):
    for zh, vi in GLOSSARY.items():
        text = text.replace(zh, vi)
    return text

import concurrent.futures

def batch_translate_zh_to_vi_multi(texts, api_keys, retries=3, delay=10):
    """
    Dá»‹ch má»™t danh sÃ¡ch vÄƒn báº£n, chia thÃ nh cÃ¡c batch nhá».
    Tá»± Ä‘á»™ng phÃ¢n phá»‘i cho cÃ¡c API key vÃ  thá»­ láº¡i vá»›i key khÃ¡c náº¿u má»™t key háº¿t quota.
    """
    results = [None] * len(texts)
    batch_size = 3  # Dá»‹ch 3 má»¥c má»—i láº§n Ä‘á»ƒ trÃ¡nh quÃ¡ táº£i
    untranslated_batches = list(enumerate([texts[i:i+batch_size] for i in range(0, len(texts), batch_size)]))
    active_key_indices = list(range(len(api_keys)))

    def translate_batch(batch, key_idx):
        api_key = api_keys[key_idx]
        api_url = API_URL_TEMPLATE.format(api_key)
        joined_texts = "\n".join(batch)
        prompt = (
            "Báº¡n lÃ  má»™t chuyÃªn gia dá»‹ch thuáº­t tiáº¿ng Trung - Viá»‡t, cÃ³ hiá»ƒu biáº¿t sÃ¢u sáº¯c vá» game mobile Trung Quá»‘c, Ä‘áº·c biá»‡t lÃ  'Nghá»‹ch Thá»§y HÃ n Mobile'.\n"
            "HÃ£y dá»‹ch táº¥t cáº£ cÃ¡c Ä‘oáº¡n sau sang **tiáº¿ng Viá»‡t tá»± nhiÃªn, sÃºc tÃ­ch, Ä‘Ãºng vÄƒn phong giá»›i game thá»§ Viá»‡t**, giá»¯ thá»© tá»± dÃ²ng.\n\n"
            "âš ï¸ Quy táº¯c dá»‹ch:\n"
            "- Giá»¯ nguyÃªn cÃ¡c cá»¥m sá»‘ (nhÆ° 10W, 288).\n"
            "- Giá»¯ nguyÃªn tÃªn ká»¹ nÄƒng, vÅ© khÃ­, tÃ­nh nÄƒng trong dáº¥u [] hoáº·c ã€ã€‘.\n"
            "- Æ¯u tiÃªn tá»« ngá»¯ phá»• biáº¿n trong cá»™ng Ä‘á»“ng game nhÆ°: 'build', 'phá»‘i Ä‘á»“', 'Ä‘áº­p Ä‘á»“', 'lá»™ trÃ¬nh', 'trang bá»‹ xá»‹n', 'ngoáº¡i hÃ¬nh Ä‘á»‰nh', 'top server'...\n"
            "- CÃ¡c tá»« cá»‘ Ä‘á»‹nh pháº£i dá»‹ch Ä‘Ãºng theo báº£ng sau:\n"
            "- æµ = lá»‘i chÆ¡i\n- æœ¨æ¡© = cá»c gá»—\n- æ²§æ¾œ = ThÆ°Æ¡ng Lan\n- æ½®å…‰ = Triá»u Quang\n- ç„æœº = Huyá»n CÆ¡\n- é¾™åŸ = Long NgÃ¢m\n- ç¥ç›¸ = Tháº§n TÆ°Æ¡ng\n- è¡€æ²³ = Huyáº¿t HÃ \n- ç¢æ¢¦ = ToÃ¡i Má»™ng\n- ç´ é—® = Tá»‘ Váº¥n\n- ä¹çµ = Cá»­u Linh\n- é“è¡£ = Thiáº¿t Y\n\n"
            "ğŸš« KhÃ´ng Ä‘Æ°á»£c thÃªm báº¥t ká»³ ghi chÃº, sá»‘ thá»© tá»±, hoáº·c pháº§n má»Ÿ Ä‘áº§u. Chá»‰ dá»‹ch tá»«ng dÃ²ng, giá»¯ nguyÃªn thá»© tá»± gá»‘c.\n\n"
            + joined_texts
        )
        headers = {"Content-Type": "application/json"}
        payload = {"contents": [{"parts": [{"text": prompt}]}]}
        try:
            response = requests.post(api_url, headers=headers, json=payload, timeout=90)
            if response.status_code == 200:
                result = response.json()
                raw_text = result["candidates"][0]["content"]["parts"][0]["text"]
                lines = [fix_terms(line.strip()) for line in cleanup_translation(raw_text).split('\n') if line.strip()]
                return lines, None
            elif response.status_code == 429:
                return None, "quota_exceeded"
            else:
                print(f"âš ï¸ Lá»—i API khÃ´ng xÃ¡c Ä‘á»‹nh vá»›i key {key_idx}. Status: {response.status_code}\n{response.text}")
                return None, "api_error"
        except requests.exceptions.RequestException as e:
            print(f"âš ï¸ Lá»—i káº¿t ná»‘i vá»›i key {key_idx}: {e}")
            return None, "connection_error"

    while untranslated_batches and active_key_indices:
        with concurrent.futures.ThreadPoolExecutor(max_workers=len(active_key_indices)) as executor:
            future_to_batch = {}
            key_iterator = iter(active_key_indices)
            # Gá»­i cÃ¡c batch chÆ°a dá»‹ch Ä‘i
            for batch_idx, batch_content in untranslated_batches:
                try:
                    key_idx = next(key_iterator)
                    future = executor.submit(translate_batch, batch_content, key_idx)
                    future_to_batch[future] = (batch_idx, batch_content, key_idx)
                except StopIteration:
                    break # Háº¿t key Ä‘á»ƒ phÃ¢n phá»‘i

            processed_batches = []
            for future in concurrent.futures.as_completed(future_to_batch):
                batch_idx, batch_content, key_idx = future_to_batch[future]
                processed_batches.append((batch_idx, batch_content))
                try:
                    lines, error_type = future.result()
                    if lines:
                        start_pos = batch_idx * batch_size
                        results[start_pos:start_pos + len(lines)] = lines
                    elif error_type == "quota_exceeded":
                        print(f"ğŸ”‘ Key {key_idx} háº¿t quota. Loáº¡i bá» khá»i danh sÃ¡ch hoáº¡t Ä‘á»™ng.")
                        if key_idx in active_key_indices:
                            active_key_indices.remove(key_idx)
                except Exception as exc:
                    print(f"âŒ Batch {batch_idx} gÃ¢y ra exception: {exc}")

            # Cáº­p nháº­t danh sÃ¡ch cÃ¡c batch chÆ°a dá»‹ch thÃ nh cÃ´ng
            all_processed_indices = {item[0] for item in processed_batches}
            untranslated_batches = [item for item in untranslated_batches if item[0] not in all_processed_indices]

    # Äiá»n ná»™i dung gá»‘c cho cÃ¡c pháº§n khÃ´ng dá»‹ch Ä‘Æ°á»£c
    for i, res in enumerate(results):
        if res is None:
            results[i] = texts[i]
            print(f"âš ï¸ KhÃ´ng dá»‹ch Ä‘Æ°á»£c má»¥c {i}, sá»­ dá»¥ng ná»™i dung gá»‘c.")

    return results

def fetch_articles(url):
    print("ğŸ” Äang láº¥y dá»¯ liá»‡u tá»« album...")
    headers = {
        "User-Agent": "Mozilla/5.0",
        "Accept": "application/json, text/plain, */*",
        "Referer": "https://mp.weixin.qq.com/",
        "X-Requested-With": "XMLHttpRequest"
    }
    resp = requests.get(url, headers=headers)
    data = resp.json()

    articles_raw = data.get("getalbum_resp", {}).get("article_list", [])
    items = []

    weekdays_vi = [
        "Thá»© Hai", "Thá»© Ba", "Thá»© TÆ°", "Thá»© NÄƒm",
        "Thá»© SÃ¡u", "Thá»© Báº£y", "Chá»§ Nháº­t"
    ]

    for art in articles_raw:
        title = art["title"]
        url = art["url"]
        cover = art.get("cover_img_1_1") or art.get("cover") or ""
        timestamp = int(art.get("create_time", 0))
        dt = datetime.utcfromtimestamp(timestamp)
        weekday = weekdays_vi[dt.weekday()]
        date_str = f"{dt.strftime('%H:%M')} - {weekday}, {dt.strftime('%d/%m')}"

        items.append({
            "title": title,
            "url": url,
            "cover_img": cover,
            "timestamp": timestamp,
            "date": date_str
        })

    print(f"âœ… {len(items)} bÃ i viáº¿t")
    return items

from bs4 import BeautifulSoup

def fetch_article_content(url):
    """
    Láº¥y ná»™i dung text vÃ  hÃ¬nh áº£nh tá»« má»™t bÃ i viáº¿t chi tiáº¿t trÃªn WeChat.
    Tráº£ vá» dict: {"content_text": ..., "images": [list link áº£nh], "content_html": ...}
    """
    headers = {
        "User-Agent": "Mozilla/5.0",
        "Accept": "text/html,application/xhtml+xml,application/xml",
        "Referer": "https://mp.weixin.qq.com/",
    }
    resp = requests.get(url, headers=headers)
    resp.encoding = resp.apparent_encoding
    soup = BeautifulSoup(resp.text, "html.parser")
    # Ná»™i dung chÃ­nh náº±m trong div id="js_content"
    content_div = soup.find("div", id="js_content")
    if not content_div:
        return {"content_text": "", "images": [], "content_html": ""}
    # Láº¥y text
    content_text = content_div.get_text("\n", strip=True)
    # Láº¥y html
    content_html = str(content_div)
    # Láº¥y link áº£nh
    images = [img["data-src"] for img in content_div.find_all("img", attrs={"data-src": True})]
    return {"content_text": content_text, "images": images, "content_html": content_html}

def fetch_all_albums(album_urls):
    all_articles = []
    for url in album_urls:
        articles = fetch_articles(url)
        top_4 = sorted(articles, key=lambda x: x["timestamp"], reverse=True)[:4]
        all_articles.extend(top_4)
    sorted_articles = sorted(all_articles, key=lambda x: x["timestamp"], reverse=True)
    return sorted_articles

# -- MAIN --
if __name__ == "__main__":
    articles = fetch_all_albums(ALBUMS)

    news_list = []
    batch_size = 6  # Dá»‹ch tá»‘i Ä‘a 6 bÃ i/láº§n Ä‘á»ƒ tiáº¿t kiá»‡m quota, cÃ³ thá»ƒ tÄƒng/giáº£m tÃ¹y Ä‘á»™ dÃ i bÃ i
    all_titles = []
    all_contents = []
    for article in articles:
        all_titles.append(article["title"])
        # Láº¥y ná»™i dung bÃ i viáº¿t trÆ°á»›c, gom láº¡i Ä‘á»ƒ dá»‹ch batch
        content_data = fetch_article_content(article["url"])
        all_contents.append(content_data["content_text"])
        article["_images"] = content_data["images"]  # táº¡m lÆ°u images Ä‘á»ƒ dÃ¹ng sau

    # Gom batch Ä‘á»ƒ dá»‹ch
    vi_titles = []
    vi_contents = []
    quota_exceeded = False
    print("\nğŸŒ Äang dá»‹ch táº¥t cáº£ tiÃªu Ä‘á»...")
    vi_titles = batch_translate_zh_to_vi_multi(all_titles, GEMINI_API_KEYS)
    if vi_titles is None:
        print("\nâŒ ÄÃ£ dá»«ng dá»‹ch do háº¿t quota táº¥t cáº£ key. news.json sáº½ chá»©a ná»™i dung gá»‘c!")
        vi_titles = all_titles
    time.sleep(2)
    print("ğŸŒ Äang dá»‹ch táº¥t cáº£ ná»™i dung...")
    vi_contents = batch_translate_zh_to_vi_multi(all_contents, GEMINI_API_KEYS)
    if vi_contents is None:
        print("\nâŒ ÄÃ£ dá»«ng dá»‹ch do háº¿t quota táº¥t cáº£ key. news.json sáº½ chá»©a ná»™i dung gá»‘c!")
        vi_contents = all_contents
    time.sleep(2)

    for idx, article in enumerate(articles):
        raw_title = article["title"]
        raw_content = all_contents[idx]
        vi_title = vi_titles[idx] if idx < len(vi_titles) and vi_titles[idx] else raw_title
        vi_content = vi_contents[idx] if idx < len(vi_contents) and vi_contents[idx] else raw_content
        if re.search(r'[\u4e00-\u9fff]', vi_title) or re.search(r'[\u4e00-\u9fff]', vi_content):
            print(f"âš ï¸ BÃ i {idx+1}: Dá»‹ch chÆ°a hoÃ n chá»‰nh!")
        print(f"â¡ï¸ {vi_title}")
        news_list.append({
            "title_zh": raw_title,
            "title_vi": vi_title,
            "content_zh": raw_content,
            "content_vi": vi_content,
            "url": article["url"],
            "cover_img": article["cover_img"],
            "images": article["_images"],
            "date": article["date"]
        })

    with open("news.json", "w", encoding="utf-8") as f:
        json.dump(news_list, f, ensure_ascii=False, indent=2)

    print("\nğŸ‰ HoÃ n táº¥t! ÄÃ£ táº¡o file news.json vá»›i ná»™i dung vÃ  hÃ¬nh áº£nh.")

    # Render luÃ´n news_full.html
    def render_news_html(news_json_path, output_html_path):
        with open(news_json_path, "r", encoding="utf-8") as f:
            news_list = json.load(f)

        html = [
            "<html>",
            "<head>",
            "<meta charset='utf-8'>",
            "<title>Tin tá»©c dá»‹ch Ä‘áº§y Ä‘á»§</title>",
            "<style>body{font-family:sans-serif;max-width:800px;margin:auto;background:#f7f7f7;}h1,h2{color:#2b4f81;}article{background:#fff;padding:24px 32px;margin:32px 0;border-radius:10px;box-shadow:0 2px 8px #0001;}img{max-width:100%;margin:16px 0;border-radius:6px;}</style>",
            "</head>",
            "<body>",
            "<h1>Tin tá»©c dá»‹ch Ä‘áº§y Ä‘á»§</h1>"
        ]
        for news in news_list:
            html.append("<article>")
            html.append(f"<h2>{news['title_vi']}</h2>")
            html.append(f"<div style='color:#888;font-size:14px;margin-bottom:8px'>{news['date']}</div>")
            if news.get("cover_img"):
                html.append(f"<img src='{news['cover_img']}' alt='cover' loading='lazy'>")
            # Ná»™i dung bÃ i viáº¿t
            html.append("<div style='white-space:pre-line;font-size:17px;line-height:1.7;margin:18px 0 0 0'>")
            html.append(news['content_vi'].replace("\n", "<br>"))
            html.append("</div>")
            # áº¢nh trong bÃ i
            if news.get("images"):
                for img_url in news["images"]:
                    html.append(f"<img src='{img_url}' alt='áº£nh bÃ i viáº¿t' loading='lazy'>")
            html.append("</article>")
        html.append("</body></html>")
        with open(output_html_path, "w", encoding="utf-8") as f:
            f.write("\n".join(html))
        print(f"âœ… ÄÃ£ táº¡o {output_html_path}")

    render_news_html("news.json", "news_full.html")
