import requests
import json
import os
import re
from datetime import datetime

# -- Cáº¥u hÃ¬nh --
API_KEY = os.environ["GEMINI_API_KEY"]
MODEL = "gemini-1.5-flash"
API_URL = f"https://generativelanguage.googleapis.com/v1/models/{MODEL}:generateContent?key={API_KEY}"

# -- Album nguá»“n --
ALBUMS = [
    "https://mp.weixin.qq.com/mp/appmsgalbum?action=getalbum&__biz=MzU5NjU1NjY1Mw==&album_id=3447004682407854082&f=json",
    "https://mp.weixin.qq.com/mp/appmsgalbum?action=getalbum&__biz=MzkyMjc1NzEzOA==&album_id=3646379824391471108&f=json",
    "https://mp.weixin.qq.com/mp/appmsgalbum?action=getalbum&__biz=MzI1MDQ1MjUxNw==&album_id=3664489989179457545&f=json"
]

# -- Báº£ng tá»« chuyÃªn ngÃ nh cá»‘ Ä‘á»‹nh --
GLOSSARY = {
    "æœ¨æ¡©": "cá»c gá»—",
    "æ²§æ¾œ": "ThÆ°Æ¡ng Lan",
    "æ½®å…‰": "Triá»u Quang",
    "ç„æœº": "Huyá»n CÆ¡",
    "é¾™åŸ": "Long NgÃ¢m",
    "ç¥ç›¸": "Tháº§n TÆ°Æ¡ng",
    "è¡€æ²³": "Huyáº¿t HÃ ",
    "ç¢æ¢¦": "ToÃ¡i Má»™ng",
    "ç´ é—®": "Tá»‘ Váº¥n",
    "ä¹çµ": "Cá»­u Linh",
    "é“è¡£": "Thiáº¿t Y"
}

def cleanup(text):
    text = re.sub(r"\*\*.*?\*\*", "", text)
    text = re.sub(r"\n+", "\n", text)
    return text.strip()

def fix_terms(text):
    for zh, vi in GLOSSARY.items():
        text = text.replace(zh, vi)
    return text

def call_gemini(prompt):
    headers = {"Content-Type": "application/json"}
    payload = { "contents": [ { "parts": [ { "text": prompt } ] } ] }
    response = requests.post(API_URL, headers=headers, json=payload)
    if response.status_code == 200:
        return response.json()["candidates"][0]["content"]["parts"][0]["text"]
    else:
        print("âŒ Lá»—i Gemini:", response.status_code)
        return None

def batch_translate_titles(titles):
    prompt = (
        "Báº¡n lÃ  má»™t chuyÃªn gia dá»‹ch thuáº­t tiáº¿ng Trung - Viá»‡t, cÃ³ hiá»ƒu biáº¿t sÃ¢u sáº¯c vá» game mobile Trung Quá»‘c, Ä‘áº·c biá»‡t lÃ  'Nghá»‹ch Thá»§y HÃ n Mobile'.\n"
        "HÃ£y dá»‹ch táº¥t cáº£ cÃ¡c tiÃªu Ä‘á» sau sang **tiáº¿ng Viá»‡t tá»± nhiÃªn, sÃºc tÃ­ch, Ä‘Ãºng vÄƒn phong giá»›i game thá»§ Viá»‡t**, mang mÃ u sáº¯c háº¥p dáº«n, Æ°u tiÃªn giá»¯ nguyÃªn cÃ¡c thuáº­t ngá»¯ ká»¹ thuáº­t, tÃªn váº­t pháº©m, vÃ  cáº¥u trÃºc tiÃªu Ä‘á» gá»‘c.\n\n"
        "âš ï¸ Quy táº¯c dá»‹ch:\n"
        "- Giá»¯ nguyÃªn cÃ¡c cá»¥m sá»‘ (nhÆ° 10W, 288).\n"
        "- Giá»¯ nguyÃªn tÃªn ká»¹ nÄƒng, vÅ© khÃ­, tÃ­nh nÄƒng trong dáº¥u [] hoáº·c ã€ã€‘.\n"
        "- Æ¯u tiÃªn tá»« ngá»¯ phá»• biáº¿n trong cá»™ng Ä‘á»“ng game nhÆ°: 'build', 'phá»‘i Ä‘á»“', 'Ä‘áº­p Ä‘á»“', 'lá»™ trÃ¬nh', 'trang bá»‹ xá»‹n', 'ngoáº¡i hÃ¬nh Ä‘á»‰nh', 'top server'...\n"
        "- CÃ¡c tá»« cá»‘ Ä‘á»‹nh pháº£i dá»‹ch Ä‘Ãºng theo báº£ng sau:\n"
        + "\n".join([f"- {zh} = {vi}" for zh, vi in GLOSSARY.items()]) +
        "\n\nğŸš« KhÃ´ng Ä‘Æ°á»£c thÃªm báº¥t ká»³ ghi chÃº, sá»‘ thá»© tá»±, hoáº·c pháº§n má»Ÿ Ä‘áº§u.\n"
        "Chá»‰ dá»‹ch tá»«ng dÃ²ng tÆ°Æ¡ng á»©ng vá»›i danh sÃ¡ch sau:\n\n"
        + "\n".join([f"{i+1}. {t}" for i, t in enumerate(titles)])
    )
    text = call_gemini(prompt)
    if not text: return titles
    return [fix_terms(line.strip()) for line in cleanup(text).split("\n") if line.strip()]

def translate_full_article(content):
    prompt = (
        "Báº¡n lÃ  má»™t biÃªn táº­p viÃªn chuyÃªn dá»‹ch ná»™i dung game mobile Trung Quá»‘c sang tiáº¿ng Viá»‡t.\n"
        "HÃ£y dá»‹ch ná»™i dung bÃ i viáº¿t sau sang **tiáº¿ng Viá»‡t rÃµ rÃ ng, tá»± nhiÃªn, Ä‘Ãºng ngá»¯ cáº£nh** nhÆ° thá»ƒ Ä‘ang viáº¿t bÃ i Ä‘Äƒng chÃ­nh thá»©c cho fanpage game â€œNghá»‹ch Thá»§y HÃ n Mobileâ€.\n\n"
        "âš ï¸ Quy táº¯c báº¯t buá»™c:\n"
        "- KhÃ´ng Ä‘á»ƒ sÃ³t hoáº·c giá»¯ láº¡i tiáº¿ng Trung gá»‘c.\n"
        "- KhÃ´ng thÃªm báº¥t ká»³ chÃº thÃ­ch hay pháº§n giá»›i thiá»‡u khÃ´ng cÃ³ trong bÃ i gá»‘c.\n"
        "- DÃ¹ng giá»ng vÄƒn dá»… hiá»ƒu, gáº§n gÅ©i, mang phong cÃ¡ch truyá»n thÃ´ng game.\n"
        "âš ï¸ Quy táº¯c dá»‹ch:\n"
        "- Giá»¯ nguyÃªn cÃ¡c cá»¥m sá»‘ (nhÆ° 10W, 288).\n"
        "- Giá»¯ nguyÃªn tÃªn ká»¹ nÄƒng, vÅ© khÃ­, tÃ­nh nÄƒng trong dáº¥u [] hoáº·c ã€ã€‘.\n"
        "- Æ¯u tiÃªn tá»« ngá»¯ phá»• biáº¿n trong cá»™ng Ä‘á»“ng game nhÆ°: 'build', 'phá»‘i Ä‘á»“', 'Ä‘áº­p Ä‘á»“', 'lá»™ trÃ¬nh', 'trang bá»‹ xá»‹n', 'ngoáº¡i hÃ¬nh Ä‘á»‰nh', 'top server'...\n"
        "- CÃ¡c tá»« cá»‘ Ä‘á»‹nh pháº£i dá»‹ch Ä‘Ãºng theo báº£ng sau:\n"
        + "\n".join([f"- {zh} = {vi}" for zh, vi in GLOSSARY.items()]) +
        "\n\nğŸš« Tuyá»‡t Ä‘á»‘i khÃ´ng sá»­ dá»¥ng tá»« ngá»¯ cá»©ng nháº¯c kiá»ƒu mÃ¡y dá»‹ch. KhÃ´ng dá»‹ch thÃ´ kiá»ƒu \"ngÆ°á»i chÆ¡i cÃ³ thá»ƒ tiáº¿n hÃ nh nháº­n\", hÃ£y viáº¿t: \"game thá»§ cÃ³ thá»ƒ nháº­n\", hoáº·c \"báº¡n cÃ³ thá»ƒ nháº­n\"...\n\n"
        "DÆ°á»›i Ä‘Ã¢y lÃ  ná»™i dung cáº§n dá»‹ch:\n"
        "---\n" + content
    )
    result = call_gemini(prompt)
    return fix_terms(cleanup(result)) if result else ""

def fetch_articles(album_url):
    headers = {"User-Agent": "Mozilla/5.0"}
    r = requests.get(album_url, headers=headers)
    data = r.json()
    items = []
    for a in data.get("getalbum_resp", {}).get("article_list", []):
        timestamp = int(a.get("create_time", 0))
        dt = datetime.utcfromtimestamp(timestamp)
        weekday = ["Thá»© Hai", "Thá»© Ba", "Thá»© TÆ°", "Thá»© NÄƒm", "Thá»© SÃ¡u", "Thá»© Báº£y", "Chá»§ Nháº­t"][dt.weekday()]
        date_str = f"{dt.strftime('%H:%M')} - {weekday}, {dt.strftime('%d/%m')}"
        items.append({
            "title": a["title"],
            "url": a["url"],
            "cover_img": a.get("cover_img_1_1") or a.get("cover"),
            "timestamp": timestamp,
            "date": date_str
        })
    return sorted(items, key=lambda x: x["timestamp"], reverse=True)[:4]

def fetch_all_articles():
    all = []
    for url in ALBUMS:
        all.extend(fetch_articles(url))
    return sorted(all, key=lambda x: x["timestamp"], reverse=True)

def save_article_html(file_id, title, date, content, cover):
    os.makedirs("news_articles", exist_ok=True)
    path = f"news_articles/{file_id}.html"
    content_html = content.replace('\n', '<br>')
    with open(path, "w", encoding="utf-8") as f:
        f.write(f"""<!DOCTYPE html>
<html lang="vi">
<head>
  <meta charset="UTF-8">
  <title>{title}</title>
  <link href="https://fonts.googleapis.com/css2?family=Roboto&display=swap" rel="stylesheet">
  <style>
    body {{ font-family: Roboto, sans-serif; line-height: 1.6; max-width: 800px; margin: 40px auto; padding: 0 20px; }}
    h1 {{ color: #00ffaa; }}
    .date {{ color: #999; font-size: 14px; margin-bottom: 20px; }}
    img.cover {{ max-width: 100%; border-radius: 10px; margin: 20px 0; }}
  </style>
</head>
<body>
  <h1>{title}</h1>
  <div class="date">{date}</div>
  <img class="cover" src="{cover}" alt="Cover">
  <div>{content_html}</div>
</body>
</html>""")

if __name__ == "__main__":
    print("ğŸ” Äang láº¥y bÃ i viáº¿t tá»« cÃ¡c album...")
    articles = fetch_all_articles()
    zh_titles = [a["title"] for a in articles]

    print("\nğŸŒ Äang dá»‹ch tiÃªu Ä‘á»...")
    vi_titles = batch_translate_titles(zh_titles)

    news_json = []
    for i, art in enumerate(articles):
        title_vi = vi_titles[i] if i < len(vi_titles) else art["title"]
        article_id = str(art["timestamp"])
        print(f"ğŸ“„ [{i+1}] {title_vi}")

        try:
            resp = requests.get(art["url"], headers={"User-Agent": "Mozilla/5.0"})
            html = resp.text
            content_match = re.search(
    r'<div class="rich_media_content[^>]*?>(.*?)</div>\s*<div class="rich_media_area_extra"',
    html,
    re.S
)
            content_html = content_match.group(1) if content_match else ""
            content_text = re.sub("<.*?>", "", content_html)
            content_text = re.sub(r"\s{2,}", " ", content_text.strip())

            print("ğŸ“ Äang dá»‹ch bÃ i viáº¿t...")
            translated = translate_full_article(content_text)

            save_article_html(article_id, title_vi, art["date"], translated, art["cover_img"])
        except Exception as e:
            print("âš ï¸ Lá»—i xá»­ lÃ½ ná»™i dung:", e)
            continue

        news_json.append({
            "title_zh": art["title"],
            "title_vi": title_vi,
            "url": f"news_articles/{article_id}.html",
            "cover_img": art["cover_img"],
            "date": art["date"]
        })

    with open("news.json", "w", encoding="utf-8") as f:
        json.dump(news_json, f, ensure_ascii=False, indent=2)

    print("\nğŸ‰ HoÃ n táº¥t! File news.json + HTML Ä‘Ã£ Ä‘Æ°á»£c táº¡o.")
